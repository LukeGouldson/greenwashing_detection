{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10860348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb9720bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7039dd5758424687bc8f30ccd9bd56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'date', 'truthRating', 'ratingName', 'author', 'headline', 'named_entities_claim', 'named_entities_article', 'keywords', 'source', 'sourceURL', 'link', 'language'],\n",
       "        num_rows: 797\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"data/claimsKGmini.csv\")\n",
    "dataset\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5356eb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'http://data.gesis.org/claimskg/claim_review/34867b12-14f7-5b5d-a92b-0955d8c1456a',\n",
       " 'text': 'Earth has not warmed for the last 17 years.',\n",
       " 'date': '2014-03-11',\n",
       " 'truthRating': 2,\n",
       " 'ratingName': 'MIXTURE',\n",
       " 'author': 'Unknown',\n",
       " 'headline': \"Climate change skeptic Patrick Moore says Earth has 'not warmed for the last 17 years'\",\n",
       " 'named_entities_claim': '2013 State of the Union,Aleutians,Amchitka Island,American nuclear weapons,Bob Beckel,Boulder,Climate Change,El Niño,Fox News,Global surface temperatures,Goddard Institute,Goddard Institute for Space Studies,Greenpeace,Greenpeace Canada,Hannity,Intergovernmental Panel on Climate Change,Kevin Trenberth,March 11,NASA,NOAA,National Center for Atmospheric Research,Patrick Moore,Phyllis Cormack,PolitiFact,President Barack Obama,PunditFact,Sean Hannity,United Nations,University of Maine,carbon emissions,cherry-picked,cherry-picking,climate change,climate change research,cold weather,combat climate change,degrees Celsius,global surface temperatures,greenhouse gas emissions,ice core,nuclear energy industry,nuclear industry,nuclear test,pundit,rising sea levels,sea ice,statistically significant,theory of climate change,tree rings',\n",
       " 'named_entities_article': 'Earth',\n",
       " 'keywords': 'http://data.gesis.org/claimskg/keyword/01b97136-3a92-50bf-9aac-ab9eab792743',\n",
       " 'source': 'politifact',\n",
       " 'sourceURL': 'http://www.politifact.com',\n",
       " 'link': 'https://www.politifact.com/factchecks/2014/mar/17/patrick-moore/climate-change-skeptic-patrick-moore-says-earth-ha/',\n",
       " 'language': 'English'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataset[\"train\"]\n",
    "train_data[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf2c52e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e794b12747f840f98ef8bfbece0f4dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22aac4e410c54e6ca0abb5e2c8d5c52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db5d5db1f9a4e93b5c7d84811bdfb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a5515f6ba143f1a248b4d53f4a1cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a8b029fa76418cbf043c756d443fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42567573cb684031bd582a1cdd85c82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"climatebert/environmental-claims\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc52e74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: NASA admitted that climate change occurs naturally as a result of changes in Earth's solar orbit and not anthropogenic factors.\n",
      "Tokenised: ['NASA', 'Ġadmitted', 'Ġthat', 'Ġclimate', 'Ġchange', 'Ġoccurs', 'Ġnaturally', 'Ġas', 'Ġa', 'Ġresult', 'Ġof', 'Ġchanges', 'Ġin', 'ĠEarth', \"'s\", 'Ġ', 'solar', 'Ġorbit', 'Ġand', 'Ġnot', 'Ġanthrop', 'ogenic', 'Ġ', 'factors', '.']\n"
     ]
    }
   ],
   "source": [
    "sample_text = train_data[0][\"text\"]\n",
    "print(\"Original text:\", sample_text)\n",
    "print(\"Tokenised:\", tokenizer.tokenize(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ba0dc017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b064b4a59ce4edd99518558c409c03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/797 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Obama administration’s own Environmental Protection Agency has said its Clean Power Plan will have a marginal impact on climate change.\n",
      "[0, 133, 1284, 42220, 50416, 282, 50267, 29, 308, 6982, 5922, 3131, 34, 26, 63, 10326, 3029, 5427, 40, 33, 10, 14612, 913, 15, 2147, 464, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def custom_tokenize(examples):\n",
    "    # The longest entry in the claimKGmini.csv is 65 words long however we don't know how many tokens this is...\n",
    "    # Actually we know that the max is 76 so we can set this. But run this again when we add more data\n",
    "    return tokenizer(examples[\"text\"], max_length=100, padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_training_dataset = train_data.map(custom_tokenize, batched=True)\n",
    "\n",
    "# Just for viewing purposes. Input_ids are the tokens, and attention_masks are whether they represent actual words or not.\n",
    "# The max_length is set to 512 so every entry has been padded to be this long which seems unnecessary\n",
    "print(tokenized_training_dataset[19][\"text\"])\n",
    "print(tokenized_training_dataset[19][\"input_ids\"])\n",
    "print(tokenized_training_dataset[19][\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb25121d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to find the max token length in the dataset\n",
    "# Please reset max_length and padding parameters in above code cell before running this\n",
    "\n",
    "lengths = [len(tokens) for tokens in tokenized_training_dataset[\"input_ids\"]]\n",
    "max = 0\n",
    "for l in lengths:\n",
    "    if l > max:\n",
    "        max = l\n",
    "max"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ClimatEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
